# (52) Анализ текстов

#### **Преподаватель**

{% content-ref url="../prepodavateli/anton-trubakov.md" %}
[anton-trubakov.md](../prepodavateli/anton-trubakov.md)
{% endcontent-ref %}

**Перезачет**

Хор(5) за факультетский курс (если был)

#### Экстерн

Задание с устным обсуждением или пройденный профильный курс на курсере (или аналогичный). Лучше сначала прислать ссылку на курс, чтобы проверить, что он подойдет

#### **Программа**&#x20;

1\. Обзор задач.\
Неформальное описание и примеры использования: классификации текстов (по теме, автору, тональности и т.д.), кластеризации текстов и тематического моделирования, извлечения словосочетаний и ключевых слов, тегирование последовательностей слов, поиск похожих текстов, аннотирование.\
\
2\. Извлечение признаков из текстов и семантическая близость текстов.\
Tf\*idf, n-граммы, нормализация токенов. Пакеты nltk, sklearn, gensim. Извлечение признаков из текстов, документация и примеры: sklearn tutorial, nltk-book. Корпусы текстов (НКРЯ, OpenCorpora, Brown, 20newsgroups, reuters).\
\
3\. Классификация текстов(общая идея, вероятностная модель). \
Вероятностные модели PLSA, LDA, ARTM. Разбор примеров из gensim tutorial. Связь с задачами матричных разложений. Проблема неединственности разложения и сложности интерпретации модели.\
\
4\. Кластеризация текстов\
Особенности работы с разреженными признаками, выбор алгоритмов. Классификация\
текстов по теме. Задача определения автора. Задача анализа тональности текста.\
Переобучение нелинейных классификаторов на разреженных признаках (пример из\
документации sklearn). Простой сентимент-анализ твитов. Сентимент-анализ с отбором\
признаков. Использование sklearn из nltk. Сравнение эффективности отбора признаков при использовании разных алгоритмов классификации.\
\
5\. Языковые модели\
Сравнение разных алгоритмов кластеризации на нескольких темах из 20newsgroups или\
reuters по метрикам, использующим и не использующим разметку. Использование\
кластеризации для снижения пространства признаков.\
\
6\. Аннотирование и матричные разложения\
Генерация текстов с помощью языковой модели. Классификация спама: сравнение оценки\
вероятности возникновения текста в униграммной и в биграммной модели, сравнение\
качества классификации.\
\
7\. Тематическое моделирование\
разложения (unsupervised алгоритмы). Графовые алгоритмы. Алгоритмы на основе\
тематического моделирования и кластеризации. Multi-document summarization. Простое\
аннотирование на кластеризации.\
\
8\. Тегирование последовательностей слов\
POS-tagging, Named Entity Recognition. HMM, MEMM вместе с выводом алгоритмов Viterbi, Forward-Backward, Baum-Velch\


9\. Краткий обзор последних достижений\
the-state-of-the-art алгоритмы. Обзор неохваченных и не раскрытых полностью вопросов.\
Обзор изученных на курсе вопросов, консультация к экзамену.

#### Зависимости

{% content-ref url="31-mashinka.2.md" %}
[31-mashinka.2.md](31-mashinka.2.md)
{% endcontent-ref %}

{% content-ref url="44-python.2.md" %}
[44-python.2.md](44-python.2.md)
{% endcontent-ref %}



#### Дополнительно

Курс читается осенью.
